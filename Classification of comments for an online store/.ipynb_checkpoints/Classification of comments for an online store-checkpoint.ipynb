{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue' size=5><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "<font color='blue'>Привет, Андрей! Меня зовут Павел Григорьев, и я буду проверять этот проект.<br>Моя основная цель - не указать на совершённые тобой ошибки, а поделиться своим опытом и помочь тебе совершенствоваться как профессионалу.<br>Спасибо за проделанную работу! Предлагаю общаться на «ты».</font>\n",
    "<details>\n",
    "\t<summary><u>Инструкция по организационным моментам (кликабельно)</u>⤵</summary>\n",
    "<font color='blue'>Я буду использовать различные цвета, чтобы было удобнее воспринимать мои комментарии:</font>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<font color='blue'>синий текст - просто текст комментария</font>\n",
    "\n",
    "<font color='green'>✔️ и зеленый текст - все отлично</font>\n",
    "\n",
    "<font color='orange'>⚠️ и оранжевый текст - сделано все правильно, однако есть рекомендации, на что стоит обратить внимание</font>\n",
    "\n",
    "<font color='red'>❌ и красный текст - есть недочеты</font>\n",
    "\n",
    "\n",
    "</details>    \n",
    "</br>\n",
    "<font color='blue'>Пожалуйста, не удаляй мои комментарии в случае возврата работы, так будет проще разобраться, какие были недочеты, а также сразу увидеть исправленное. </font>\n",
    "\n",
    "<font color='blue'>Ответы на мои комментарии лучше тоже помечать.\n",
    "\n",
    "Например:</font><font color='purple'><b>Комментарий студента</b></font>\n",
    "\n",
    "<font color='blue'><b>Давай смотреть, что получилось!</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue' size=3><b>Комментарий ревьюера 3</b></font>\n",
    "\n",
    "<font color='blue'>Привет еще раз. Спасибо, за исправления. Оформление комментариев по работе сохраняется. </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Установка-сторонних-библиотек\" data-toc-modified-id=\"Установка-сторонних-библиотек-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Установка сторонних библиотек</a></span></li><li><span><a href=\"#Импорт-библиотек\" data-toc-modified-id=\"Импорт-библиотек-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Импорт библиотек</a></span></li><li><span><a href=\"#Константы\" data-toc-modified-id=\"Константы-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Константы</a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Установка сторонних библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Error parsing requirements for jupyter-highlight-selected-word: [Errno 2] No such file or directory: '/Users/andreyalekseev/anaconda3/envs/practicum/lib/python3.9/site-packages/jupyter_highlight_selected_word-0.2.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U torch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Error parsing requirements for jupyter-highlight-selected-word: [Errno 2] No such file or directory: '/Users/andreyalekseev/anaconda3/envs/practicum/lib/python3.9/site-packages/jupyter_highlight_selected_word-0.2.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Error parsing requirements for jupyter-highlight-selected-word: [Errno 2] No such file or directory: '/Users/andreyalekseev/anaconda3/envs/practicum/lib/python3.9/site-packages/jupyter_highlight_selected_word-0.2.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'> Хорошее оформление импортов! \\\n",
    "Импорты собраны в одной ячейке, разделены на функциональные группы.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 713"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments = pd.read_csv('/Users/andreyalekseev/Documents_local/Yandex.Disk.localized/Practicum/11. ML for text/Project/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавлено во второй итерации\n",
    "\n",
    "try:\n",
    "    comments = pd.read_csv(\n",
    "        '/datasets/toxic_comments.csv'\n",
    "    )\n",
    "except:\n",
    "    comments = pd.read_csv(\n",
    "        'https://code.s3.yandex.net/datasets/toxic_comments.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ❌\\\n",
    "<font color='red'> ~~Ошибка исполнения кода. Данные должны загружаться у тех, кому ты демонстрируешь свою работу.~~</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ⚠️\\\n",
    "<font color='darkorange'> Данные Практикума можно загружать напрямую с базы:\\\n",
    "`data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93718</th>\n",
       "      <td>93810</td>\n",
       "      <td>\"\\n\\n \"\"Snuff me!\"\" \\n\\nhttp://www.kinkyceline...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140134</th>\n",
       "      <td>140286</td>\n",
       "      <td>Oh, did little mrs. pussy get his feelings hur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91575</th>\n",
       "      <td>91666</td>\n",
       "      <td>\"\\n\\n Leopard again \\n\\nHey Cas,\\n\\na while ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95840</th>\n",
       "      <td>95932</td>\n",
       "      <td>\"\\n\\n Jessie Stephen \\n\\n\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119855</th>\n",
       "      <td>119960</td>\n",
       "      <td>Chuvashia LGBT\\nYeah, I created that page awhi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48801</th>\n",
       "      <td>48856</td>\n",
       "      <td>Stop Faking\\nYou are not an administrator and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21592</th>\n",
       "      <td>21612</td>\n",
       "      <td>Within Temptation \\nThe band has nothing to do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136721</th>\n",
       "      <td>136859</td>\n",
       "      <td>\"Please do not replace Wikipedia pages with bl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108391</th>\n",
       "      <td>108488</td>\n",
       "      <td>More Modern Greek Art \\n\\nAnyone care to help ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103269</th>\n",
       "      <td>103366</td>\n",
       "      <td>What is your problem.  \\n\\nEveryone on the tal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "93718        93810  \"\\n\\n \"\"Snuff me!\"\" \\n\\nhttp://www.kinkyceline...      0\n",
       "140134      140286  Oh, did little mrs. pussy get his feelings hur...      1\n",
       "91575        91666  \"\\n\\n Leopard again \\n\\nHey Cas,\\n\\na while ba...      0\n",
       "95840        95932                         \"\\n\\n Jessie Stephen \\n\\n\"      0\n",
       "119855      119960  Chuvashia LGBT\\nYeah, I created that page awhi...      0\n",
       "48801        48856  Stop Faking\\nYou are not an administrator and ...      1\n",
       "21592        21612  Within Temptation \\nThe band has nothing to do...      0\n",
       "136721      136859  \"Please do not replace Wikipedia pages with bl...      0\n",
       "108391      108488  More Modern Greek Art \\n\\nAnyone care to help ...      0\n",
       "103269      103366  What is your problem.  \\n\\nEveryone on the tal...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Появилась неизвестная колонка. Ее можно сравнить с индексом, но в ней хватает 159 индексов. По каким то причинам они не попали к нам. Ценности в этом признаке не видно и просто полезной информации извлечь не получается. Удалим этот признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>Данные загружены корректно, первичный осмотр проведен.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = comments[['text', 'toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    143106\n",
       "1     16186\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Положительный класс в целевом признаке(токсичность комментариев) очевидно уступает отрицательному классу. Есть дисбаланс и положительные комментарии(отрицательный класс) кратно превосходят отрицаетльные комментарии. Скорее всего так в жизни и происходит - негативных комментариев меньше.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'> Мы обнаружили серьёзный дисбаланс при исследовании данных. Как дополнительные материалы, рекомендую статью <a href='https://dyakonov.org/2021/05/27/imbalance/'>Дисбаланс классов</a>, очень классная, как и весь блог Дьяконова. Ещё такой <a href='https://github.com/Dyakonov/ml_hacks/blob/master/book_disbalance_public_v1.ipynb'>ноутбук</a> есть.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем на два класса(положительный и отрицательный) \n",
    "# в них выбираем по 4000 случайных строк и объединяем\n",
    "\n",
    "# comments = pd.concat(\n",
    "#     [\n",
    "#         comments[comments['toxic'] == 0].sample(4000, random_state=RANDOM_STATE), \n",
    "#         comments[comments['toxic'] == 1].sample(4000, random_state=RANDOM_STATE)\n",
    "#     ]).sample(8000, random_state=RANDOM_STATE\n",
    "# ).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ❌\\\n",
    "<font color='red'> ~~Мы не можем балансировать весь датасет, поскольку в этом случае мы балансируем также тестовую выборку. С такой тестовой выборкой метрика не сможет адекватно оценить работу модели на входящих данных с реальным распределением таргетов.~~ </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавлено во второй итерации\n",
    "\n",
    "# Отделяем тестовые данные, выберем случайные 4000 строк\n",
    "# Тренировочные данные разбиваем на два класса(положительный и отрицательный) \n",
    "# в них выбираем по 2000 случайных строк и объединяем\n",
    "\n",
    "comments_test = comments.sample(4000, random_state=RANDOM_STATE)\n",
    "\n",
    "comments = comments.drop(comments_test.index)\n",
    "\n",
    "# comments = pd.concat(\n",
    "#     [\n",
    "#         comments[comments['toxic'] == 0].sample(2000, random_state=RANDOM_STATE), \n",
    "#         comments[comments['toxic'] == 1].sample(2000, random_state=RANDOM_STATE)\n",
    "#     ]).sample(4000, random_state=RANDOM_STATE\n",
    "# ).reset_index(drop=True)\n",
    "\n",
    "comments = comments.sample(4000, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "comments_test = comments_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    3599\n",
       "1     401\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    3610\n",
       "1     390\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_test['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Загружаем токенизатор BERT\n",
    "# tokenizer = transformers.BertTokenizer(\n",
    "#     vocab_file='/Users/andreyalekseev/Documents_local/Yandex.Disk.localized/Practicum/11. ML for text/Project/rubert_cased_L-12_H-768_A-12_pt_v1/vocab.txt')\n",
    "\n",
    "# # Токенизируем каждую строку\n",
    "# tokenized = comments['text'].apply(\n",
    "#     lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "# # Находим максимальную длину токенов\n",
    "# max_len = 0\n",
    "# for i in tokenized.values:\n",
    "#     if len(i) > max_len:\n",
    "#         max_len = len(i)\n",
    "\n",
    "# # Заполняем остатки строк, которые короче самой длинной, нулями\n",
    "# padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "# #Обрежем тензор, так как при создании эмбеддингов возможна работа только с векторами размерностью до 512\n",
    "# padded = padded[:,:512]\n",
    "\n",
    "# # Создадим маску\n",
    "# attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ❌\\\n",
    "<font color='red'> ~~У меня нет файла `vocab.txt`. А также `config.json` и `pytorch_model.bin`\\\n",
    "Токенизатр и модель лучше загружать напрямую из `transformers`. (там ещё можно и выбрать получше 😊)~~</font>\n",
    "```python\n",
    "model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, transformers.BertTokenizer, '<имя_модели>')\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model_bert = model_class.from_pretrained(pretrained_weights)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreyalekseev/anaconda3/envs/practicum/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (948 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Загружаем токенизатор BERT\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('unitary/toxic-bert')\n",
    "\n",
    "# Токенизируем каждую строку\n",
    "tokenized = comments['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "tokenized_test = comments_test['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера : </b></font> ✔️\\\n",
    "<font color='green'> Для этой задачи существуют специальные модели, например 'unitary/toxic-bert'</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Находим максимальную длину токенов\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "max_len_test = 0\n",
    "for i in tokenized_test.values:\n",
    "    if len(i) > max_len_test:\n",
    "        max_len_test = len(i)\n",
    "\n",
    "# Заполняем остатки строк, которые короче самой длинной, нулями\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "padded_test = np.array([i + [0]*(max_len_test - len(i)) for i in tokenized_test.values])\n",
    "\n",
    "#Обрежем тензор, так как при создании эмбеддингов возможна работа только с векторами размерностью до 512\n",
    "padded = padded[:,:512]\n",
    "padded_test = padded_test[:,:512]\n",
    "\n",
    "# Создадим маску\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask_test = np.where(padded_test != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем файл конфигурации\n",
    "# config = transformers.BertConfig.from_json_file(\n",
    "#     '/Users/andreyalekseev/Documents_local/Yandex.Disk.localized/Practicum/11. ML for text/Project/rubert_cased_L-12_H-768_A-12_pt_v1/config.json')\n",
    "\n",
    "config = transformers.BertConfig.from_pretrained(\"unitary/toxic-bert\")\n",
    "\n",
    "# Загружаем модель\n",
    "# model = transformers.BertModel.from_pretrained(\n",
    "#     '/Users/andreyalekseev/Documents_local/Yandex.Disk.localized/Practicum/11. ML for text/Project/rubert_cased_L-12_H-768_A-12_pt_v1/pytorch_model.bin', config=config)\n",
    "\n",
    "model = transformers.BertModel.from_pretrained(\"unitary/toxic-bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера 3: </b></font> ✔️\\\n",
    "<font color='green'> Отличный выбор модели! Есть мнение, что она обучалась на этих данных.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b9bf2adace4369a5a464d7bd53b963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создаем эмбеддинги, размер батча выставим 100, что бы не давать пиковую грузки на железо\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6170fcb0c54241b1a857524faa0694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создаем эмбеддинги, размер батча выставим 100, что бы не давать пиковую грузки на железо\n",
    "batch_size = 100\n",
    "embeddings_test = []\n",
    "for i in notebook.tqdm(range(padded_test.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded_test[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_test_batch = torch.LongTensor(attention_mask_test[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_test_batch)\n",
    "        \n",
    "        embeddings_test.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем тренировочные и тестовые выборки\n",
    "features_train = np.concatenate(embeddings)\n",
    "features_test = np.concatenate(embeddings_test)\n",
    "y_train = comments['toxic']\n",
    "y_test = comments_test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя метрика на кросс валидации: 0.9565314635850761\n",
      "Лучшие параметры модели {'C': 0.6, 'penalty': 'l1'}\n",
      "CPU times: user 621 ms, sys: 780 ms, total: 1.4 s\n",
      "Wall time: 56.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(max_iter=400, random_state=RANDOM_STATE, solver='liblinear')\n",
    "# lr.fit(features_train, y_train)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(\n",
    "    lr, \n",
    "    param_grid, \n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_lr.fit(features_train, y_train)\n",
    "print ('Средняя метрика на кросс валидации:', grid_search_lr.best_score_)\n",
    "print('Лучшие параметры модели', grid_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера 2: </b></font> ❌\\\n",
    "<font color='red'>~~Кроссвалидация на сбалансированных данных даёт не корректную оценку. Лучше проверять на несбалансированной валидационной выборке.~~</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера 3: </b></font> ✔️\\\n",
    "<font color='green'> 👍</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера 2: </b></font> ❌\\\n",
    "<font color='blue'> Можно делать кросс-валидацию на сбалансированных данных, если балансировщик соединён с классификатором в Пайплайне. Балансировщики и Пайплайн для этого нужно брать из библиотеки `imblearn`.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ❌\\\n",
    "<font color='red'> ~~Нужно проверить несколько моделей и выбрать Лучшую.\\\n",
    "Для этого их нужно оценить кросс-валидацией или на валидационных данных.~~</font>\n",
    "```text\n",
    "2. Обучите разные модели.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя метрика на кросс валидации: 0.9448888628462049\n",
      "Лучшие параметры модели {'metric': 'cityblock', 'n_neighbors': 9}\n",
      "CPU times: user 349 ms, sys: 122 ms, total: 472 ms\n",
      "Wall time: 1min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreyalekseev/anaconda3/envs/practicum/lib/python3.9/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': range(2, 10),\n",
    "    'metric': ['minkowski', 'euclidean', 'cityblock']\n",
    "}\n",
    "\n",
    "grid_search_knn = GridSearchCV(\n",
    "    knn, \n",
    "    param_grid, \n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_knn.fit(features_train, y_train)\n",
    "print ('Средняя метрика на кросс валидации:', grid_search_knn.best_score_)\n",
    "print('Лучшие параметры модели', grid_search_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя метрика на кросс валидации: 0.9561583011056329\n",
      "Лучшие параметры модели {'C': 100, 'degree': 5}\n",
      "CPU times: user 3.13 s, sys: 541 ms, total: 3.67 s\n",
      "Wall time: 6min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svc = SVC(kernel='poly',random_state=RANDOM_STATE, probability=True)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1,1,10,100],\n",
    "    'degree': range(3, 10)\n",
    "}\n",
    "\n",
    "grid_search_svc_poly = GridSearchCV(\n",
    "    svc, \n",
    "    param_grid, \n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_svc_poly.fit(features_train, y_train)\n",
    "print ('Средняя метрика на кросс валидации:', grid_search_svc_poly.best_score_)\n",
    "print('Лучшие параметры модели', grid_search_svc_poly.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Лучшая модель SVC с полиномиальным ядром. Сделаем предсказания на ней.~~\n",
    "\n",
    "Лучшая модель - это логистическая регрессия. Сделаем предсказания на ней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_search_lr.best_estimator_.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9578544061302682"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"border-radius: 10px; box-shadow: 2px 2px 2px; border: 1px solid; padding: 10px \"> \n",
    "<b>Комментарий студента v.1</b> \n",
    "    \n",
    "Привет! Видимо правда тестовую выборку нельзя было балансировать. И теперь с несбалансированной тестовой выборкой метрика не очень( Не понимаю куда смотреть? Что можно улучшить? \n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера 2: </b></font> ⚠️\\\n",
    "<font color='darkorange'>\n",
    "Что можно попробовать:\n",
    "- Векторизаторы NLTK (TfIdf, Bow) \n",
    "- Методы работы с дисбалансом,\n",
    "- Регуляризация,\n",
    "- Обучить полный классификатор BERT\n",
    "- Использовать спец. модели для этой задачи.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"border-radius: 10px; box-shadow: 2px 2px 2px; border: 1px solid; padding: 10px \"> \n",
    "<b>Комментарий студента v.2</b> \n",
    "    \n",
    "Со специальной моделью 'unitary/toxic-bert' получился отличный результат! спасибо за подсказку! \n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика на тестовых данных получилась ~~0.79~~ 0.958, что больше 0.75.\n",
    "Логистическая регрессия хорошо себя показала. \n",
    "У нас получилась модель, которая может отлично предсказывать токсичность комментариев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>Очень приятно видеть вывод в конце проекта! В выводах можно приводить полученные ранее значения. Также можно расписать все, что было сделано в ходе проведения работы. Представь, что тебе заплатят исходя из объёма сделанных тобой выводов )).</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Итоговый комментарий ревьюера</b></font>\\\n",
    "<font color='green'>Андрей, хороший проект получился!\n",
    "Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "Выводы и рассуждения получились содержательными, их было интересно читать.\n",
    "</font>\n",
    "\n",
    "<font color='steelblue'>Над проектом ещё стоит поработать - есть рекомендации по дополнению некоторых твоих шагов проекта. Такие рекомендации я отметил жёлтыми комментариями. Будет здорово, если ты учтёшь их - так проект станет структурно и содержательно более совершенным.\n",
    "\n",
    "Также в работе есть критические замечания. К этим замечаниям я оставил пояснительные комментарии красного цвета, в которых перечислил возможные варианты дальнейших действий. Уверен, ты быстро с этим управишься:)\n",
    "\n",
    "Если о том, что нужно сделать в рамках комментариев, будут возникать вопросы - оставь их, пожалуйста, в комментариях, и я отвечу на них во время следующего ревью.\n",
    "\n",
    "Также буду рад ответить на любые твои вопросы по проекту или на какие-либо другие, если они у тебя имеются - оставь их в комментариях, и я постараюсь ответить:)</font>\n",
    "\n",
    "<font color='blue'><b>Жду твой проект на повторном ревью. До встречи :) </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Итоговый комментарий ревьюера 2</b></font>\\\n",
    "<font color='green'>Андрей, хороший проект получился!\n",
    "Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "</font>\n",
    "\n",
    "<font color='blue'>Что нужно исправить:</font>\n",
    "<ul><font color='red'>Не Проводи кросс-валидацию на сбалансированных данных.</font></ul>\n",
    "<ul><font color='red'>Построй модель со значением метрики качества F1 не меньше 0.75 на тестовых данных. </font></ul>\n",
    "\n",
    "<font color='blue'>Что можно сделать лучше:</font>\n",
    "<font color='orange'>В работе я оставил несколько советов. Буду рад, если ты учтешь их.</font></ul>\n",
    "\n",
    "<font color='blue'><b>Жду новую версию проекта :)</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Итоговый комментарий ревьюера 2</b></font>\\\n",
    "<font color='green'>Андрей, проект принят! \\\n",
    "Все этапы пройдены. Все рекомендации учтены.\\\n",
    "Надеюсь, тебе понравился процесс выполнения и результат.</font> \\\n",
    "<font color='blue'><b>Спасибо, удачи в освоении профессии!</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b> \\\n",
    "Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = []\n",
    "model.cuda()   # закидываем модель на GPU\n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "\n",
    "features = np.concatenate(embeddings)\n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "\n",
    "\n",
    "NLP от Samsung https://stepik.org/course/54098/promo \\\n",
    "NLP от Huawei https://ods.ai/tracks/nlp-course-spring-2024 \\\n",
    "Transformers от Hugging Face https://huggingface.co/learn/nlp-course/ru/chapter1/1\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 164309,
    "start_time": "2024-06-15T18:03:10.192Z"
   },
   {
    "duration": 2331,
    "start_time": "2024-06-15T18:05:54.504Z"
   },
   {
    "duration": 28531,
    "start_time": "2024-06-15T18:06:15.028Z"
   },
   {
    "duration": 14968,
    "start_time": "2024-06-15T18:06:43.561Z"
   },
   {
    "duration": 15419,
    "start_time": "2024-06-15T18:06:58.531Z"
   },
   {
    "duration": 3,
    "start_time": "2024-06-15T18:07:13.952Z"
   },
   {
    "duration": 164,
    "start_time": "2024-06-15T18:07:13.957Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
